{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T15:47:40.184122Z",
     "start_time": "2025-06-26T15:47:37.932200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "import visualkeras\n",
    "from PIL import ImageFont"
   ],
   "id": "4356415226f0cea2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T15:47:41.743579Z",
     "start_time": "2025-06-26T15:47:40.199128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "font = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "\n",
    "# --- Constants for Model 1 ---\n",
    "LEARNING_RATE      = 5e-4\n",
    "IMG_HEIGHT         = 256\n",
    "IMG_WIDTH          = 256\n",
    "\n",
    "def build_attention_cnn(img_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    inp = layers.Input(shape=(*img_size, 1), name='input_image')\n",
    "\n",
    "    # --- CNN Backbone ---\n",
    "    def cnn_block(x, filters, prefix):\n",
    "        x = layers.Conv2D(filters, 3, padding='same',\n",
    "                          kernel_regularizer=regularizers.l2(1e-4),\n",
    "                          name=f'{prefix}_conv_a')(x)\n",
    "        x = layers.BatchNormalization(name=f'{prefix}_bn_a')(x)\n",
    "        x = layers.Activation('relu', name=f'{prefix}_relu_a')(x)\n",
    "        x = layers.Conv2D(filters, 3, padding='same',\n",
    "                          kernel_regularizer=regularizers.l2(1e-4),\n",
    "                          name=f'{prefix}_conv_b')(x)\n",
    "        x = layers.BatchNormalization(name=f'{prefix}_bn_b')(x)\n",
    "        x = layers.Activation('relu', name=f'{prefix}_relu_b')(x)\n",
    "        return layers.MaxPooling2D(2, 2, name=f'{prefix}_pool')(x)\n",
    "\n",
    "    x = inp\n",
    "    # Using fewer blocks for a more compact visualization, but the principle is the same.\n",
    "    # for i, f in enumerate([32, 64, 128, 256, 256], start=1):\n",
    "    for i, f in enumerate([32, 64, 128], start=1): # Reduced for brevity in visualization\n",
    "        x = cnn_block(x, f, prefix=f'block{i}')\n",
    "\n",
    "    # --- Spatial Attention ---\n",
    "    avg_pool = layers.Lambda(lambda t: tf.reduce_mean(t, axis=-1, keepdims=True),\n",
    "                             name='att_avg_pool')(x)\n",
    "    max_pool = layers.Lambda(lambda t: tf.reduce_max(t, axis=-1, keepdims=True),\n",
    "                             name='att_max_pool')(x)\n",
    "\n",
    "    concat   = layers.Concatenate(name='att_concat')([avg_pool, max_pool])\n",
    "    att_mid  = layers.Conv2D(32, 5, padding='same', activation='relu',\n",
    "                              name='att_inter_conv')(concat)\n",
    "    att_map  = layers.Conv2D(1, 7, padding='same', activation='sigmoid',\n",
    "                              use_bias=False, name='att_final_conv')(att_mid)\n",
    "    x = layers.Multiply(name='apply_attention')([x, att_map])\n",
    "\n",
    "    # --- Regression Head ---\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    for units, drop, name in [(512, .4, 'fc1'), (256, .4, 'fc2')]: # Reduced for brevity\n",
    "        x = layers.Dense(units, activation='relu',\n",
    "                         kernel_regularizer=regularizers.l2(1e-4),\n",
    "                         name=f'{name}_dense')(x)\n",
    "        x = layers.BatchNormalization(name=f'{name}_bn')(x)\n",
    "        x = layers.Dropout(drop, name=f'{name}_dropout')(x)\n",
    "\n",
    "    lin_out = layers.Dense(1, name='age_linear',\n",
    "                           kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    out     = layers.Activation('relu', name='age_output')(lin_out)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out, name='AttentionCNN')\n",
    "    return model\n",
    "\n",
    "attention_cnn_model = build_attention_cnn()\n",
    "\n",
    "visualkeras.layered_view(\n",
    "    attention_cnn_model,\n",
    "    legend=True,\n",
    "    font=font, spacing = 80,\n",
    "    to_file='pngs/attention_cnn_model.png'\n",
    ").show() # .show() will display the plot directly if in an interactive environment"
   ],
   "id": "ef2a676e1f119c77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alepa\\PycharmProjects\\pythonProject\\venvBIO\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alepa\\PycharmProjects\\pythonProject\\venvBIO\\Lib\\site-packages\\visualkeras\\layered.py:86: UserWarning: The legend_text_spacing_offset parameter is deprecated and will be removed in a future release.\n",
      "  warnings.warn(\"The legend_text_spacing_offset parameter is deprecated and will be removed in a future release.\")\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T15:47:42.252706Z",
     "start_time": "2025-06-26T15:47:41.937029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SIZE = 256\n",
    "INPUT_SHAPE = (SIZE, SIZE, 1)\n",
    "GENDER_FEATURE_SHAPE = (1,)\n",
    "\n",
    "def build_dual_cnn(input_shape, gender_shape):\n",
    "    # inputs\n",
    "    image_input = keras.Input(shape=input_shape, name=\"image_input\")\n",
    "    gender_input = keras.Input(shape=gender_shape, name=\"gender_input\")\n",
    "\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', name='conv1a')(image_input)\n",
    "    x = layers.BatchNormalization(name='bn1a')(x)\n",
    "    x = layers.Activation('relu', name='relu1a')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), name='pool1')(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', name='conv2a')(x)\n",
    "    x = layers.BatchNormalization(name='bn2a')(x)\n",
    "    x = layers.Activation('relu', name='relu2a')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), name='pool2')(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', name='conv3a')(x)\n",
    "    x = layers.BatchNormalization(name='bn3a')(x)\n",
    "    x = layers.Activation('relu', name='relu3a')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), name='pool3')(x)\n",
    "\n",
    "    # feature extraction\n",
    "    image_features = layers.GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "\n",
    "    # fusion with gender\n",
    "    concatenated_features = layers.concatenate([image_features, gender_input],\n",
    "                                               name='concatenate_features')\n",
    "\n",
    "    # regression head\n",
    "    x = layers.Dense(128, name='dense_head1')(concatenated_features)\n",
    "    x = layers.BatchNormalization(name='bn_head1')(x)\n",
    "    x = layers.Activation('relu', name='relu_head1')(x)\n",
    "    x = layers.Dropout(0.4, name='dropout_head')(x)\n",
    "\n",
    "    bone_age_output = layers.Dense(1, activation='linear', name='bone_age_output')(x)\n",
    "\n",
    "    model = keras.Model(\n",
    "        inputs=[image_input, gender_input],\n",
    "        outputs=bone_age_output,\n",
    "        name=\"Dual_Input_CNN\")\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "dual_cnn_model = build_dual_cnn(INPUT_SHAPE, GENDER_FEATURE_SHAPE)\n",
    "\n",
    "# Generate the visualization\n",
    "visualkeras.layered_view(\n",
    "    dual_cnn_model,\n",
    "    legend=True,\n",
    "    font=font, spacing = 80,\n",
    "    to_file='pngs/dual_cnn_model.png'\n",
    ").show()\n",
    "\n",
    "print(\"Saved 'dual_cnn_model.png'\")\n"
   ],
   "id": "594684255671735a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alepa\\PycharmProjects\\pythonProject\\venvBIO\\Lib\\site-packages\\visualkeras\\layered.py:86: UserWarning: The legend_text_spacing_offset parameter is deprecated and will be removed in a future release.\n",
      "  warnings.warn(\"The legend_text_spacing_offset parameter is deprecated and will be removed in a future release.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 'dual_cnn_model.png'\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T15:47:42.887968Z",
     "start_time": "2025-06-26T15:47:42.288920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SIZE = 320\n",
    "CHANNELS = 1\n",
    "PATCH_SIZE = 48\n",
    "PATCH_DIM = (PATCH_SIZE ** 2) * CHANNELS\n",
    "OVERLAP = 0.25\n",
    "STRIDE = int(PATCH_SIZE * (1 - OVERLAP))\n",
    "num_patches_per_side = (SIZE - PATCH_SIZE) // STRIDE + 1\n",
    "N_PATCHES = num_patches_per_side ** 2\n",
    "INPUT_SHAPE = (N_PATCHES, PATCH_DIM)\n",
    "GENDER_FEATURE_SHAPE = (1,)\n",
    "\n",
    "def build_bid_rnn(input_shape, gender_shape,\n",
    "                 patch_size=PATCH_SIZE, channels=CHANNELS,\n",
    "                 patch_embed_dim=112, rnn_units=[112, 112, 56]):\n",
    "    # 1) Inputs & reshape\n",
    "    image_input  = keras.Input(shape=input_shape,  name=\"image_input\")\n",
    "    gender_input = keras.Input(shape=gender_shape, name=\"gender_input\")\n",
    "    num_patches, _ = input_shape\n",
    "    x = layers.Reshape((num_patches, patch_size, patch_size, channels),\n",
    "                       name=\"reshape_patches\")(image_input)\n",
    "\n",
    "    # 2) Smaller Conv2D patch encoder\n",
    "    patch_encoder = keras.Sequential([\n",
    "        layers.Conv2D(32, kernel_size=4, padding=\"same\", activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(patch_embed_dim, activation=\"relu\"),\n",
    "    ], name=\"patch_encoder\")\n",
    "    x = layers.TimeDistributed(patch_encoder, name=\"patch_embedding\")(x)\n",
    "\n",
    "    # 3) Positional embeddings\n",
    "    pos_emb_layer = layers.Embedding(input_dim=num_patches,\n",
    "                                     output_dim=patch_embed_dim,\n",
    "                                     name=\"pos_embedding\")\n",
    "    pos_indices = tf.range(num_patches, dtype=tf.int32)\n",
    "    pos_emb = tf.expand_dims(pos_emb_layer(pos_indices), axis=0)\n",
    "    x = layers.Add(name=\"add_positional\")([x, pos_emb])\n",
    "\n",
    "    # 4) Reduced Biâ€‘GRU stack\n",
    "    for i, units in enumerate(rnn_units, start=1):\n",
    "        return_seq = (i < len(rnn_units))\n",
    "        x = layers.Bidirectional(\n",
    "                layers.GRU(units, return_sequences=return_seq),\n",
    "                name=f\"bi_gru{i}\"\n",
    "            )(x)\n",
    "        x = layers.BatchNormalization(name=f\"bn_gru{i}\")(x)\n",
    "    image_features = x\n",
    "\n",
    "    # 5) Slimmer dense head\n",
    "    x = layers.concatenate([image_features, gender_input],\n",
    "                           name='concatenate_features')\n",
    "    x = layers.Dense(128, name='dense_head1')(x)\n",
    "    x = layers.BatchNormalization(name='bn_head1')(x)\n",
    "    x = layers.Activation('relu', name='relu_head1')(x)\n",
    "    x = layers.Dropout(0.4, name='dropout_head1')(x)\n",
    "\n",
    "    bone_age_output = layers.Dense(1, activation='linear', name='bone_age_output')(x)\n",
    "\n",
    "    model = keras.Model(inputs=[image_input, gender_input],\n",
    "                        outputs=bone_age_output,\n",
    "                        name=\"Patch_BiRNN_Model\")\n",
    "    return model\n",
    "\n",
    "bid_rnn_model = build_bid_rnn(\n",
    "    input_shape=(N_PATCHES, PATCH_DIM),\n",
    "    gender_shape=GENDER_FEATURE_SHAPE)\n",
    "\n",
    "visualkeras.layered_view(\n",
    "    bid_rnn_model,\n",
    "    legend=True,\n",
    "    font=font,\n",
    "    to_file='pngs/bid_rnn_model.png',\n",
    "    spacing=80\n",
    ").show()"
   ],
   "id": "1a5c4b6159411b00",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T15:47:42.902832Z",
     "start_time": "2025-06-26T15:47:42.899271Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d0324715d3884a7e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
