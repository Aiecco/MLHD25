{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Bone Age Assessment Pipeline - Jupyter Notebook\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook aggregates and orchestrates the various components of a system for automated bone age prediction from hand radiographs. It includes functionalities for image preprocessing, dataset building, defining a deep learning model with spatial attention, model training and evaluation, and result visualization.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Original Project Structure:**\\n\",\n",
    "    \"The code was originally organized into Python modules within a `src/` folder structure.\\n\",\n",
    "    \"\\n\",\n",
    "    \"```\\n\",\n",
    "    \"project_root/\\n\",\n",
    "    \"├── data/\\n\",\n",
    "    \"│   ├── Train/\\n\",\n",
    "    \"│   │   ├── train_labels.csv\\n\",\n",
    "    \"│   │   └── raw_images/ (original images)\\n\",\n",
    "    \"│   │   └── prep_images/ (preprocessed images)\\n\",\n",
    "    \"│   ├── Val/\\n\",\n",
    "    \"│   │   ├── val_labels.csv\\n\",\n",
    "    \"│   │   └── raw_images/\\n\",\n",
    "    \"│   │   └── prep_images/\\n\",\n",
    "    \"│   └── Test/\\n\",\n",
    "    \"│       ├── test_labels.csv\\n\",\n",
    "    \"│       └── raw_images/\\n\",\n",
    "    \"│       └── prep_images/\\n\",\n",
    "    \"├── src/\\n\",\n",
    "    \"│   ├── dataset/\\n\",\n",
    "    \"│   │   └── radiograph_dataset_builder.py\\n\",\n",
    "    \"│   ├── Models/\\n\",\n",
    "    \"│   │   ├── AttentionLayer.py\\n\",\n",
    "    \"│   │   └── age_prediction_model.py\\n\",\n",
    "    \"│   ├── plot/\\n\",\n",
    "    \"│   │   ├── plot_evaluation.py\\n\",\n",
    "    \"│   │   └── plot_training_history.py\\n\",\n",
    "    \"│   ├── preprocessing/\\n\",\n",
    "    \"│   │   ├── PreprocessImage.py\\n\",\n",
    "    \"│   │   └── PreprocessPipeline.py\\n\",\n",
    "    \"│   ├── testing/\\n\",\n",
    "    \"│   │   └── EvaluationPipeline.py\\n\",\n",
    "    \"│   ├── training/\\n\",\n",
    "    \"│   │   └── training_pipeline.py\\n\",\n",
    "    \"│   └── utils/\\n\",\n",
    "    \"│       └── load_model.py\\n\",\n",
    "    \"└── main.py\\n\",\n",
    "    \"```\\n\",\n",
    "    \"\\n\",\n",
    "    \"For this notebook to run, it is crucial that the `data/` folder structure and the CSV/image files are correctly placed relative to the notebook.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Necessary Imports\\n\",\n",
    "    \"\\n\",\n",
    "    \"This section imports all required Python libraries and TensorFlow/Keras modules for code execution.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import os\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"from tensorflow.keras import layers, regularizers, models\\n\",\n",
    "    \"from tensorflow.keras.callbacks import History # For type hinting\\n\",\n",
    "    \"from matplotlib import pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Imports for image preprocessing libraries (e.g., OpenCV, scikit-image)\\n\",\n",
    "    \"# Ensure they are installed in your environment (e.g., pip install opencv-python scikit-image)\\n\",\n",
    "    \"import cv2 # Assuming the use of OpenCV for some imaging operations\\n\",\n",
    "    \"from skimage.exposure import equalize_adapthist # For CLAHE\\n\",\n",
    "    \"from skimage.transform import resize\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# To ensure TensorFlow does not allocate all GPU memory on startup\\n\",\n",
    "    \"gpus = tf.config.experimental.list_physical_devices('GPU')\\n\",\n",
    "    \"if gpus:\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        # Currently, memory growth needs to be the same across GPUs\\n\",\n",
    "    \"        for gpu in gpus:\\n\",\n",
    "    \"            tf.config.experimental.set_memory_growth(gpu, True)\\n\",\n",
    "    \"        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\\n\",\n",
    "    \"        print(len(gpus), \\\"Physical GPUs,\\\", len(logical_gpus), \\\"Logical GPUs\\\")\\n\",\n",
    "    \"    except RuntimeError as e:\\n\",\n",
    "    \"        # Memory growth must be set before GPUs have been initialized\\n\",\n",
    "    \"        print(e)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Custom Class and Function Definitions\\n\",\n",
    "    \"\\n\",\n",
    "    \"This section includes the definitions of the classes and functions that comprise the different modules of the system. They will be presented in logical order of dependency.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.1. `SpatialAttention` Layer (from `src/Models/AttentionLayer.py`)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class SpatialAttention(layers.Layer):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    A custom Keras layer implementing a more attentive spatial attention mechanism.\\n\",\n",
    "    \"    It now includes an intermediate convolutional layer to learn richer attention features.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def __init__(self, kernel_size=7, **kwargs):\\n\",\n",
    "    \"        super(SpatialAttention, self).__init__(**kwargs)\\n\",\n",
    "    \"        self.kernel_size = kernel_size\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Intermediate conv layer to learn more complex features from concatenated avg/max pools\\n\",\n",
    "    \"        # More filters (e.g., 8 or 16) for more capacity, smaller kernel for local patterns.\\n\",\n",
    "    \"        self.intermediate_conv = layers.Conv2D(\\n\",\n",
    "    \"            filters=32,  # Increased filters for more \\\"intelligence\\\"\\n\",\n",
    "    \"            kernel_size=5,  # Small kernel for local feature extraction within attention\\n\",\n",
    "    \"            padding='same',\\n\",\n",
    "    \"            activation='relu',  # Added ReLU activation for non-linearity\\n\",\n",
    "    \"            name='attention_intermediate_conv'\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        # Final conv layer to produce the single-channel attention map\\n\",\n",
    "    \"        self.final_conv = layers.Conv2D(\\n\",\n",
    "    \"            filters=1,\\n\",\n",
    "    \"            kernel_size=self.kernel_size,  # Use the initial kernel_size for the final aggregation\\n\",\n",
    "    \"            padding='same',\\n\",\n",
    "    \"            activation='sigmoid',  # Sigmoid to output values between 0 and 1\\n\",\n",
    "    \"            use_bias=False,\\n\",\n",
    "    \"            name='attention_final_conv'\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def build(self, input_shape):\\n\",\n",
    "    \"        # Keras will automatically build internal layers like self.intermediate_conv and self.final_conv\\n\",\n",
    "    \"        super(SpatialAttention, self).build(input_shape)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def call(self, inputs):\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        Applies spatial attention to the input feature map.\\n\",\n",
    "    \"        The attention map is now generated by a slightly deeper sub-network.\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        # Compute average and max pool along the channel axis\\n\",\n",
    "    \"        avg_pool = tf.reduce_mean(inputs, axis=-1, keepdims=True)\\n\",\n",
    "    \"        max_pool = tf.reduce_max(inputs, axis=-1, keepdims=True)\\n\",\n",
    "    \"        concat = layers.concatenate([avg_pool, max_pool], axis=-1, name='attention_concat_pools')\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Process through intermediate conv layer\\n\",\n",
    "    \"        x = self.intermediate_conv(concat)\\n\",\n",
    "    \"        # Apply final conv to get the attention map\\n\",\n",
    "    \"        attention_map = self.final_conv(x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        return inputs * attention_map\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def get_config(self):\\n\",\n",
    "    \"        config = super(SpatialAttention, self).get_config()\\n\",\n",
    "    \"        config.update({\\\"kernel_size\\\": self.kernel_size})\\n\",\n",
    "    \"        return config\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.2. `RadiographDatasetBuilder` (from `src/dataset/radiograph_dataset_builder.py`)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class RadiographDatasetBuilder:\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Builds a TensorFlow Dataset for radiograph images, handling raw and\\n\",\n",
    "    \"    preprocessed image inputs along with age labels, applying pixel standardization.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def __init__(self,\\n\",\n",
    "    \"                 base_dir,\\n\",\n",
    "    \"                 label_csv,\\n\",\n",
    "    \"                 img_subfolder=\\\"prep_images\\\",\\n\",\n",
    "    \"                 prepimg_subfolder=\\\"prep_images\\\",\\n\",\n",
    "    \"                 img_size=(128, 128),\\n\",\n",
    "    \"                 batch_size=16,\\n\",\n",
    "    \"                 mean_pixel_value: float = 0.0,  # New parameter for mean\\n\",\n",
    "    \"                 std_pixel_value: float = 1.0):  # New parameter for standard deviation\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        Initializes the dataset builder.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Args:\\n\",\n",
    "    \"            base_dir (str): The base directory containing image subfolders.\\n\",\n",
    "    \"            label_csv (str): The name of the CSV file containing image IDs and bone ages,\\n\",\n",
    "    \"                             relative to base_dir.\\n\",\n",
    "    \"            img_subfolder (str): Subfolder containing the main images to list files from.\\n\",\n",
    "    \"            prepimg_subfolder (str): Subfolder containing the preprocessed images.\\n\",\n",
    "    \"            img_size (tuple): Desired image size (height, width).\\n\",\n",
    "    \"            batch_size (int): Batch size for the dataset.\\n\",\n",
    "    \"            mean_pixel_value (float): Mean pixel value for standardizing image data.\\n\",\n",
    "    \"            std_pixel_value (float): Standard deviation of pixel values for standardizing image data.\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        self.base_dir = base_dir\\n\",\n",
    "    \"        self.img_subfolder = os.path.join(base_dir, img_subfolder)\\n\",\n",
    "    \"        self.prepimg_subfolder = os.path.join(base_dir, prepimg_subfolder)\\n\",\n",
    "    \"        self.img_size = img_size\\n\",\n",
    "    \"        self.batch_size = batch_size\\n\",\n",
    "    \"        self.mean_pixel_value = mean_pixel_value\\n\",\n",
    "    \"        self.std_pixel_value = std_pixel_value\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Read CSV and prepare age_map\\n\",\n",
    "    \"        # Corrected: label_csv should be relative to base_dir\\n\",\n",
    "    \"        df = pd.read_csv(label_csv)\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            df['filename'] = df['id'].astype(str)\\n\",\n",
    "    \"            df['age_months'] = df['boneage']\\n\",\n",
    "    \"        except KeyError:  # Handle cases where column names might be different or delimiter is ';'\\n\",\n",
    "    \"            df = pd.read_csv(label_csv, delimiter=\\\";\\\")  # Corrected path\\n\",\n",
    "    \"            df['filename'] = df['id'].astype(str)\\n\",\n",
    "    \"            df['age_months'] = df['boneage'].astype(str).str.replace(',', '.').astype(float)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        self.age_map = dict(zip(df['filename'], df['age_months']))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def _parse_function(self, filepath):\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        Parses a single image file and its corresponding preprocessed images\\n\",\n",
    "    \"        and age label, applying pixel standardization.\\n\",\n",
    "    \"        This function runs in Python context via tf.py_function.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Args:\\n\",\n",
    "    \"            filepath (tf.Tensor): The TensorFlow string tensor representing the image file path.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Returns:\\n\",\n",
    "    \"            tuple: (prep_img, age_months) as TensorFlow tensors,\\n\",\n",
    "    \"                   with images standardized.\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # 2) Extract filename stem to find corresponding preprocessed images\\n\",\n",
    "    \"        fname_tensor = tf.strings.split(filepath, os.sep)[-1]\\n\",\n",
    "    \"        stem_tensor = tf.strings.split(fname_tensor, '.')[0]\\n\",\n",
    "    \"        fname = stem_tensor.numpy().decode('utf-8')  # Python string for dict lookup and path construction\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Construct path for preprocessed image\\n\",\n",
    "    \"        prep_path = os.path.join(self.prepimg_subfolder, fname + \\\".png\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Read and resize preprocessed image\\n\",\n",
    "    \"        prep_img = tf.io.read_file(prep_path)\\n\",\n",
    "    \"        prep_img = tf.image.decode_png(prep_img, channels=1)  # Decode as grayscale\\n\",\n",
    "    \"        prep_img = tf.image.resize(prep_img, self.img_size)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Convert to float32 BEFORE standardization\\n\",\n",
    "    \"        prep_img = tf.cast(prep_img, tf.float32)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # standardization\\n\",\n",
    "    \"        std_val_safe = self.std_pixel_value if self.std_pixel_value > 1e-7 else 1.0\\n\",\n",
    "    \"\\n\",\n",
    "    \"        prep_img = (prep_img - self.mean_pixel_value) / std_val_safe\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Get age from map, handling potential comma decimal separator\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            age_months = float(self.age_map[fname])\\n\",\n",
    "    \"        except ValueError:\\n\",\n",
    "    \"            age_months = float(str(self.age_map[fname]).replace(',', '.'))\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Return all three items. The build method's _tf_parse will then select what to pass.\\n\",\n",
    "    \"        return prep_img, age_months\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def build(self, train=True):\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        Builds and returns a TensorFlow Dataset.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Args:\\n\",\n",
    "    \"            train (bool): If True, shuffles the dataset.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Returns:\\n\",\n",
    "    \"            tf.data.Dataset: A TensorFlow dataset yielding\\n\",\n",
    "    \"                             (prep_img, age_months) tuples, as per the model's current input.\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        pattern = os.path.join(self.img_subfolder, \\\"*.png\\\")\\n\",\n",
    "    \"        ds = tf.data.Dataset.list_files(pattern, shuffle=train)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        def _tf_parse(fp):\\n\",\n",
    "    \"            \\\"\\\"\\\"\\n\",\n",
    "    \"            TensorFlow-graph compatible wrapper for _parse_function.\\n\",\n",
    "    \"            \\\"\\\"\\\"\\n\",\n",
    "    \"            # _parse_function returns (prep_img, age_months)\\n\",\n",
    "    \"            img_prep, age_months = tf.py_function(\\n\",\n",
    "    \"                func=self._parse_function,\\n\",\n",
    "    \"                inp=[fp],  # Pass the filepath tensor to the py_function\\n\",\n",
    "    \"                Tout=[tf.float32, tf.float32]  # Output types of _parse_function\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Set static shapes for the output tensors\\n\",\n",
    "    \"            img_prep.set_shape((*self.img_size, 1))\\n\",\n",
    "    \"            age_months.set_shape(())\\n\",\n",
    "    \"\\n\",\n",
    "    \"            return img_prep, age_months  # Returns only the preprocessed image and age\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Map the parsing function over the dataset\\n\",\n",
    "    \"        ds = ds.map(_tf_parse, num_parallel_calls=tf.data.AUTOTUNE)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Batch and prefetch for performance\\n\",\n",
    "    \"        ds = ds.batch(self.batch_size).prefetch(tf.data.AUTOTUNE)\\n\",\n",
    "    \"        return ds\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.3. `AgePredictionModel` (from `src/Models/age_prediction_model.py`)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class AgePredictionModel:\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Represents a deep learning model for automated bone age prediction from hand radiographs.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    This model employs a multi-layered Convolutional Neural Network (CNN) backbone\\n\",\n",
    "    \"    for feature extraction, integrated with a custom spatial attention mechanism,\\n\",\n",
    "    \"    and a robust fully connected regression head. It is designed to be gender-agnostic,\\n\",\n",
    "    \"    relying solely on image-derived features for prediction.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def __init__(self, img_size=(128, 128)):\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        Initializes the AgePredictionModel.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Args:\\n\",\n",
    "    \"            img_size (tuple, optional): The target dimensions (height, width) for input images.\\n\",\n",
    "    \"                                        Defaults to (128, 128). This should match the size\\n\",\n",
    "    \"                                        used in preprocessing.\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        self.img_size = img_size\\n\",\n",
    "    \"        # Build the Keras model graph immediately upon initialization\\n\",\n",
    "    \"        self.model = self._build_model()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def _create_cnn_branch(self, input_tensor: tf.Tensor, name_prefix: str) -> tf.Tensor:\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        Constructs a single Convolutional Neural Network (CNN) branch for feature extraction.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        This branch consists of five sequential blocks, each typically comprising two\\n\",\n",
    "    \"        convolutional layers, Batch Normalization, ReLU activation, and MaxPooling.\\n\",\n",
    "    \"        The number of filters progressively increases with depth.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Args:\\n\",\n",
    "    \"            input_tensor (tf.Tensor): The input tensor to the CNN branch (e.g., image input).\\n\",\n",
    "    \"            name_prefix (str): A prefix for naming the layers within this branch\\n\",\n",
    "    \"                               to ensure uniqueness (e.g., 'prep', 'raw', 'extr').\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Returns:\\n\",\n",
    "    \"            tf.Tensor: The output tensor from the final MaxPooling layer of this CNN branch,\\n\",\n",
    "    \"                       representing extracted spatial features.\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        # Block 1: Conv -> BN -> ReLU -> Conv -> BN -> ReLU -> MaxPool\\n\",\n",
    "    \"        # Captures initial low-level features\\n\",\n",
    "    \"        x = layers.Conv2D(32, (3, 3), padding='same',\\n\",\n",
    "    \"                          kernel_regularizer=regularizers.l2(1e-4), name=f'{name_prefix}_conv1a')(input_tensor)\\n\",\n",
    "    \"        x = layers.BatchNormalization(name=f'{name_prefix}_bn1a')(x)\\n\",\n",
    "    \"        x = layers.Activation('relu', name=f'{name_prefix}_relu1a')(x)\\n\",\n",
    "    \"        x = layers.Conv2D(32, (3, 3), padding='same',\\n\",\n",
    "    \"                          kernel_regularizer=regularizers.l2(1e-4), name=f'{name_prefix}_conv1b')(x)\\n\",\n",
    "    \"        x = layers.BatchNormalization(name=f'{name_prefix}_bn1b')(x)\\n\",\n",
    "    \"        x = layers.Activation('relu', name=f'{name_prefix}_relu1b')(x)\\n\",\n",
    "    \"        x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=f'{name_prefix}_pool1')(x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Block 2: Increase filters, capture more complex features\\n\",\n",
    "    \"        x = layers.Conv2D(64, (3, 3), padding='same',\\n\",\n",
    "    \"                          kernel_regularizer=regularizers.l2(1e-4), name=f'{name_prefix}_conv2a')(x)\\n\",\n",
    "    \"        x = layers.BatchNormalization(name=f'{name_prefix}_bn2a')(x)\\n\",\n",
    "    \"        x = layers.Activation('relu', name=f'{name_prefix}_relu2a')(x)\\n\",\n",
    "    \"        x = layers.Conv2D(64, (3, 3), padding='same',\\n\",\n",
    "    \"                          kernel_regularizer=regularizers.l2(1e-4), name=f'{name_prefix}_conv2b')(x)\\n\",\n",
    "    \"        x = layers.BatchNormalization(name=f'{name_prefix}_bn2b')(x)\\n\",\n",
    "    \"        x = layers.Activation('relu', name=f'{name_prefix}_relu2b')(x)\\n\",\n",
    "    \"        x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=f'{name_prefix}_pool2')(x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Block 3: Further increase filters for higher-level feature abstraction\\n\",\n",
    "    \"        x = layers.Conv2D(128, (3, 3), padding='same',\\n\",\n",
    "    \"                          kernel_regularizer=regularizers.l2(1e-4), name=f'{name_prefix}_conv3a')(x)\\n\",\n",
    "    \"        x = layers.BatchNormalization(name=f'{name_prefix}_bn3a')(x)\\n\",\n",
    "    \"        x = layers.Activation('relu', name=f'{name_prefix}_relu3a')(x)\\n\",\n",
    "    \"        x = layers.Conv2D(128, (3, 3), padding='same',\\n\",\n",
    "    \"                          kernel_regularizer=regularizers.l2(1e-4), name=f'{name_prefix}_conv3b')(x)\\n\",\n",
    "    \"        x = layers.BatchNormalization(name=f'{name_prefix}_bn3b')(x)\\n\",\n",
    "    \"        x = layers.Activation('relu', name=f'{name_prefix}_relu3b')(x)\\n\",\n",
    "    \"        x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=f'{name_prefix}_pool3')(x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Block 4: Continue increasing filter depth\\n\",\n",
    "    \"        x = layers.Conv2D(256, (3, 3), padding='same',\\n\",\n",
    "    \"                          kernel_regularizer=regularizers.l2(1e-4), name=f'{name_prefix}_conv4a')(x)\\n\",\n",
    "    \"        x = layers.BatchNormalization(name=f'{name_prefix}_bn4a')(x)\\n\",\n",
    "    \"        x = layers.Activation('relu', name=f'{name_prefix}_relu4a')(x)\\n\",\n",
    "    \"        x = layers.Conv2D(256, (3, 3), padding='same',\\n\",\n",
    "    \"                          kernel_regularizer=regularizers.l2(1e-4), name=f'{name_prefix}_conv4b')(x)\\n\",\n",
    "    \"        x = layers.BatchNormalization(name=f'{name_prefix}_bn4b')(x)\\n\",\n",
    "    \"        x = layers.Activation('relu', name=f'{name_prefix}_relu4b')(x)\\n\",\n",
    "    \"        x = layers.MaxPooling2D((2, 2), strides=(2, 2), name=f'{name_prefix}_pool4')(x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Block 5: Final convolutional block in the backbone\\n\",\n",
    "    \"        # Note: Filter count adjusted to 512 in the theoretical write-up for deeper abstraction,\\n\",\n",
    "    \"        # but kept at 256 here based on provided code's last working state.\\n\",\n",
    "    \"        # If input size is 256x256, after 5 pools, spatial dim becomes 8x8.\\n\",\n",
    "    \"        x = layers.Conv2D(256, (3, 3), padding='same', name='conv5a',\\n\",\n",
    "    \"                          kernel_regularizer=regularizers.l2(1e-4))(x)  # Added L2 regularization for consistency\\n\",\n",
    "    \"        x = layers.BatchNormalization(name='bn5a')(x)\\n\",\n",
    "    \"        x = layers.Activation('relu', name='relu5a')(x)\\n\",\n",
    "    \"        x = layers.Conv2D(256, (3, 3), padding='same', name='conv5b',\\n\",\n",
    "    \"                          kernel_regularizer=regularizers.l2(1e-4))(x)  # Added L2 regularization for consistency\\n\",\n",
    "    \"        x = layers.BatchNormalization(name='bn5b')(x)\\n\",\n",
    "    \"        x = layers.Activation('relu', name='relu5b')(x)\\n\",\n",
    "    \"        x = layers.MaxPooling2D((2, 2), name='pool5')(x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        return x\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def _build_model(self) -> models.Model:\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        Constructs the complete Keras model for bone age prediction.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        The model integrates a CNN backbone for feature extraction,\\n\",\n",
    "    \"        a Spatial Attention layer, and a multi-layered regression head.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Returns:\\n\",\n",
    "    \"            tf.keras.Model: The compiled Keras Model instance.\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        # Define the input layer for preprocessed images.\\n\",\n",
    "    \"        # The input shape is (height, width, channels), where channels=1 for grayscale.\\n\",\n",
    "    \"        prep_input = layers.Input(shape=(*self.img_size, 1), name='prep_input')\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Create the CNN branch for feature extraction from the preprocessed input.\\n\",\n",
    "    \"        prep_features = self._create_cnn_branch(prep_input, 'prep')\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Apply the custom Spatial Attention mechanism to the extracted features.\\n\",\n",
    "    \"        # This layer selectively re-weights spatial regions, focusing on diagnostically\\n\",\n",
    "    \"        # relevant areas of the radiograph.\\n\",\n",
    "    \"        attended_prep_features = SpatialAttention(name='attention_prep')(prep_features)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Flatten the attended features to prepare for the fully connected layers.\\n\",\n",
    "    \"        x = layers.Flatten(name='flatten_features')(attended_prep_features)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # --- Regression Head: Fully Connected Layers for Age Prediction ---\\n\",\n",
    "    \"        # Dense Layer 1: Processes the flattened features.\\n\",\n",
    "    \"        # Followed by Batch Normalization and Dropout for regularization.\\n\",\n",
    "    \"        x = layers.Dense(512, activation='relu', name='dense1',\\n\",\n",
    "    \"                         kernel_regularizer=regularizers.l2(1e-4))(x)\\n\",\n",
    "    \"        x = layers.BatchNormalization(name='bn_dense1')(x)\\n\",\n",
    "    \"        x = layers.Dropout(0.4, name='dropout1')(x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Dense Layer 2: Further refines the features.\\n\",\n",
    "    \"        # Includes Batch Normalization and Dropout.\\n\",\n",
    "    \"        x = layers.Dense(256, activation='relu', name='dense2',\\n\",\n",
    "    \"                         kernel_regularizer=regularizers.l2(1e-4))(x)\\n\",\n",
    "    \"        x = layers.BatchNormalization(name='bn_dense2')(x)\\n\",\n",
    "    \"        x = layers.Dropout(0.4, name='dropout2')(x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Dense Layer 3: Adds more complexity to the mapping.\\n\",\n",
    "    \"        # Also includes Batch Normalization and Dropout.\\n\",\n",
    "    \"        x = layers.Dense(128, activation='relu', name='dense3',\\n\",\n",
    "    \"                         kernel_regularizer=regularizers.l2(1e-4))(x)\\n\",\n",
    "    \"        x = layers.BatchNormalization(name='bn_dense3')(x)\\n\",\n",
    "    \"        x = layers.Dropout(0.3, name='dropout3')(x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Final Output Layer: Predicts the bone age in months.\\n\",\n",
    "    \"        # 'linear' activation allows for any real value output.\\n\",\n",
    "    \"        # A subsequent 'relu' activation is applied to ensure predictions are non-negative.\\n\",\n",
    "    \"        output_linear = layers.Dense(1, name='age_output_linear',\\n\",\n",
    "    \"                                     kernel_regularizer=regularizers.l2(1e-4))(x)  # Added L2 for consistency\\n\",\n",
    "    \"        # Force predictions to be non-negative (bone age cannot be < 0)\\n\",\n",
    "    \"        output = layers.Activation('relu', name='age_output_relu')(output_linear)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Create the Keras Model instance, defining its inputs and outputs.\\n\",\n",
    "    \"        model = models.Model(inputs=prep_input, outputs=output, name='AgePredictionModel')\\n\",\n",
    "    \"        return model\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def compile_model(self, learning_rate: float = 0.0005):\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        Compiles the Keras model with a specified optimizer, loss function, and metrics.\\n\",\n",
    "    \"\\n\",\n",
    "    \"        Args:\\n\",\n",
    "    \"            learning_rate (float, optional): The initial learning rate for the Adam optimizer.\\n\",\n",
    "    \"                                             Defaults to 0.0005.\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"        # Use Adam optimizer for efficient training with adaptive learning rates.\\n\",\n",
    "    \"        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Compile the model specifying Mean Absolute Error (MAE) as the loss function\\n\",\n",
    "    \"        # (directly interpretable as error in months) and also track it as a metric.\\n\",\n",
    "    \"        self.model.compile(optimizer=optimizer, loss='mae', metrics=['mae'])\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.4. Image Preprocessing Functions (from `src/preprocessing/PreprocessImage.py`)\\n\",\n",
    "    \"\\n\",\n",
    "    \"These are utility functions for image manipulation.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def calculate_mean_std(image_folder_path: str, img_size=(256, 256)) -> tuple:\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Calculates the mean and standard deviation of pixel values across all images\\n\",\n",
    "    \"    in a specified folder. This is used for standardization in the model's input pipeline.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        image_folder_path (str): The path to the folder containing image files.\\n\",\n",
    "    \"        img_size (tuple): The size (height, width) to which images will be resized\\n\",\n",
    "    \"                          before calculating mean/std. Defaults to (256, 256).\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        tuple: A tuple containing (mean_pixel_value, std_pixel_value).\\n\",\n",
    "    \"               Returns (0.0, 1.0) if no images are found to prevent division by zero.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    pixel_values = []\\n\",\n",
    "    \"    image_files = [os.path.join(image_folder_path, f) for f in os.listdir(image_folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if not image_files:\\n\",\n",
    "    \"        print(f\\\"Warning: No images found in {image_folder_path}. Returning default mean=0, std=1.\\\")\\n\",\n",
    "    \"        return 0.0, 1.0\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(f\\\"Calculating mean and std from {len(image_files)} images in {image_folder_path}...\\\")\\n\",\n",
    "    \"    for i, img_path in enumerate(image_files):\\n\",\n",
    "    \"        # Read image in grayscale (0)\\n\",\n",
    "    \"        img = cv2.imread(img_path, 0)\\n\",\n",
    "    \"        if img is None:\\n\",\n",
    "    \"            print(f\\\"Warning: Could not read image {img_path}. Skipping.\\\")\\n\",\n",
    "    \"            continue\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Resize to target size (if not already that size)\\n\",\n",
    "    \"        img_resized = cv2.resize(img, img_size)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Flatten and extend the list of pixel values\\n\",\n",
    "    \"        pixel_values.extend(img_resized.flatten().tolist())\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if (i + 1) % 1000 == 0:\\n\",\n",
    "    \"            print(f\\\"Processed {i+1}/{len(image_files)} images for mean/std calculation...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    pixel_values_array = np.array(pixel_values, dtype=np.float32)\\n\",\n",
    "    \"    mean_val = np.mean(pixel_values_array)\\n\",\n",
    "    \"    std_val = np.std(pixel_values_array)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(f\\\"Calculated Mean: {mean_val:.2f}, Std: {std_val:.2f}\\\")\\n\",\n",
    "    \"    return mean_val, std_val\\n\",\n",
    "    \"\\n\",\n",
    "    \"def apply_clahe(image: np.ndarray) -> np.ndarray:\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Applies Contrast Limited Adaptive Histogram Equalization (CLAHE) to an image.\\n\",\n",
    "    \"    Assumes input image is grayscale.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        image (np.ndarray): The input grayscale image (2D numpy array).\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        np.ndarray: The CLAHE-enhanced image.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # Convert to appropriate type for skimage.exposure.equalize_adapthist (float between 0 and 1)\\n\",\n",
    "    \"    img_float = image.astype(np.float32) / 255.0\\n\",\n",
    "    \"    clahe_img = equalize_adapthist(img_float, clip_limit=0.03)\\n\",\n",
    "    \"    # Convert back to uint8 (0-255) if needed for saving or further processing\\n\",\n",
    "    \"    clahe_img_uint8 = (clahe_img * 255).astype(np.uint8)\\n\",\n",
    "    \"    return clahe_img_uint8\\n\",\n",
    "    \"\\n\",\n",
    "    \"def find_and_crop_hand(image: np.ndarray, output_size=(256, 256)) -> np.ndarray:\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Detects the hand within a grayscale X-ray image and crops it.\\n\",\n",
    "    \"    This implementation uses simple thresholding and contour finding.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        image (np.ndarray): The input grayscale image (2D numpy array).\\n\",\n",
    "    \"        output_size (tuple): The desired size (height, width) of the cropped image.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        np.ndarray: The cropped and resized image of the hand. If no hand is found,\\n\",\n",
    "    \"                    returns the original image resized.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # Simple thresholding to create a binary image\\n\",\n",
    "    \"    _, thresh = cv2.threshold(image, 20, 255, cv2.THRESH_BINARY)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Find contours\\n\",\n",
    "    \"    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if not contours:\\n\",\n",
    "    \"        print(\\\"No contours found. Returning resized original image.\\\")\\n\",\n",
    "    \"        return cv2.resize(image, output_size)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Find the largest contour (presumably the hand)\\n\",\n",
    "    \"    largest_contour = max(contours, key=cv2.contourArea)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Get bounding box for the largest contour\\n\",\n",
    "    \"    x, y, w, h = cv2.boundingRect(largest_contour)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Crop the hand using the bounding box\\n\",\n",
    "    \"    cropped_hand = image[y:y+h, x:x+w]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Resize the cropped hand to the output size\\n\",\n",
    "    \"    resized_hand = cv2.resize(cropped_hand, output_size, interpolation=cv2.INTER_AREA)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return resized_hand\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.5. Preprocessing Pipeline (from `src/preprocessing/PreprocessPipeline.py`)\\n\",\n",
    "    \"\\n\",\n",
    "    \"This function orchestrates image preprocessing operations.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def preprocess_pipeline(base_data_path: str, img_size=(256, 256), Val=False, Test=False, Train=False):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Orchestrates the preprocessing of radiograph images within a specified dataset split.\\n\",\n",
    "    \"    This includes reading raw images, applying hand detection, CLAHE enhancement, and resizing,\\n\",\n",
    "    \"    then saving the processed images to a 'prep_images' subfolder.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        base_data_path (str): The base path to the dataset split (e.g., 'data/Train/', 'data/Val/').\\n\",\n",
    "    \"        img_size (tuple): The target size (height, width) for preprocessed images. Defaults to (256, 256).\\n\",\n",
    "    \"        Val (bool): If True, indicates validation dataset preprocessing. Defaults to False.\\n\",\n",
    "    \"        Test (bool): If True, indicates test dataset preprocessing. Defaults to False.\\n\",\n",
    "    \"        Train (bool): If True, indicates training dataset preprocessing. Defaults to False.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Raises:\\n\",\n",
    "    \"        ValueError: If none of Val, Test, or Train flags are set to True.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    if not (Val or Test or Train):\\n\",\n",
    "    \"        raise ValueError(\\\"At least one of 'Val', 'Test', or 'Train' must be True.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    raw_images_path = os.path.join(base_data_path, 'raw_images')\\n\",\n",
    "    \"    prep_images_output_path = os.path.join(base_data_path, 'prep_images')\\n\",\n",
    "    \"    os.makedirs(prep_images_output_path, exist_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    image_files = [f for f in os.listdir(raw_images_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(f\\\"\\\\nStarting preprocessing for {base_data_path} with {len(image_files)} images...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for i, filename in enumerate(image_files):\\n\",\n",
    "    \"        img_path = os.path.join(raw_images_path, filename)\\n\",\n",
    "    \"        output_path = os.path.join(prep_images_output_path, filename)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Read image in grayscale\\n\",\n",
    "    \"        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\\n\",\n",
    "    \"        if img is None:\\n\",\n",
    "    \"            print(f\\\"Warning: Could not read image {img_path}. Skipping.\\\")\\n\",\n",
    "    \"            continue\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Apply preprocessing steps\\n\",\n",
    "    \"        # 1. Find and crop hand\\n\",\n",
    "    \"        cropped_img = find_and_crop_hand(img, output_size=img_size)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # 2. Apply CLAHE\\n\",\n",
    "    \"        clahe_img = apply_clahe(cropped_img)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Save the preprocessed image\\n\",\n",
    "    \"        cv2.imwrite(output_path, clahe_img)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if (i + 1) % 100 == 0:\\n\",\n",
    "    \"            print(f\\\"Processed {i+1}/{len(image_files)} images in {base_data_path}.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(f\\\"Finished preprocessing for {base_data_path}. Processed images saved to {prep_images_output_path}.\\\")\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.6. Training Pipeline (from `src/training/training_pipeline.py`)\\n\",\n",
    "    \"\\n\",\n",
    "    \"This function manages the entire model training process.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def training_pipeline(\\n\",\n",
    "    \"    base_dir_train: str,\\n\",\n",
    "    \"    label_train: str,\\n\",\n",
    "    \"    base_dir_val: str,\\n\",\n",
    "    \"    label_val: str,\\n\",\n",
    "    \"    img_sizes: int,\\n\",\n",
    "    \"    mean_pixel_value: float,\\n\",\n",
    "    \"    std_pixel_value: float,\\n\",\n",
    "    \"    existing_model=None, # Accepts None or a loaded Keras model\\n\",\n",
    "    \"    model_save_path: str = 'best_age_prediction_model.keras',\\n\",\n",
    "    \"    epochs: int = 50,\\n\",\n",
    "    \"    batch_size: int = 16,\\n\",\n",
    "    \"    learning_rate: float = 0.0005\\n\",\n",
    "    \"):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Orchestrates the complete training pipeline for the bone age prediction model.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        base_dir_train (str): Base directory for training data.\\n\",\n",
    "    \"        label_train (str): CSV file path for training labels.\\n\",\n",
    "    \"        base_dir_val (str): Base directory for validation data.\\n\",\n",
    "    \"        label_val (str): CSV file path for validation labels.\\n\",\n",
    "    \"        img_sizes (int): Side length for input images (e.g., 256 for 256x256).\\n\",\n",
    "    \"        mean_pixel_value (float): Mean pixel value for image standardization.\\n\",\n",
    "    \"        std_pixel_value (float): Standard deviation for image standardization.\\n\",\n",
    "    \"        existing_model (tf.keras.Model, optional): An already loaded Keras model to continue training.\\n\",\n",
    "    \"                                                   If None, a new model is initialized. Defaults to None.\\n\",\n",
    "    \"        model_save_path (str): Path to save the best model. Defaults to 'best_age_prediction_model.keras'.\\n\",\n",
    "    \"        epochs (int): Number of training epochs. Defaults to 50.\\n\",\n",
    "    \"        batch_size (int): Batch size for training. Defaults to 16.\\n\",\n",
    "    \"        learning_rate (float): Learning rate for the optimizer. Defaults to 0.0005.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    print(\\\"\\\\n--- Setting up Training and Validation Datasets ---\\\")\\n\",\n",
    "    \"    # Initialize dataset builders for training and validation\\n\",\n",
    "    \"    train_dataset_builder = RadiographDatasetBuilder(\\n\",\n",
    "    \"        base_dir=base_dir_train,\\n\",\n",
    "    \"        label_csv=label_train,\\n\",\n",
    "    \"        img_size=(img_sizes, img_sizes),\\n\",\n",
    "    \"        batch_size=batch_size,\\n\",\n",
    "    \"        mean_pixel_value=mean_pixel_value,\\n\",\n",
    "    \"        std_pixel_value=std_pixel_value\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    val_dataset_builder = RadiographDatasetBuilder(\\n\",\n",
    "    \"        base_dir=base_dir_val,\\n\",\n",
    "    \"        label_csv=label_val,\\n\",\n",
    "    \"        img_size=(img_sizes, img_sizes),\\n\",\n",
    "    \"        batch_size=batch_size,\\n\",\n",
    "    \"        mean_pixel_value=mean_pixel_value,\\n\",\n",
    "    \"        std_pixel_value=std_pixel_value\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Build TensorFlow datasets\\n\",\n",
    "    \"    train_ds = train_dataset_builder.build(train=True)\\n\",\n",
    "    \"    val_ds = val_dataset_builder.build(train=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"\\\\n--- Initializing Model ---\\\")\\n\",\n",
    "    \"    model_instance = None\\n\",\n",
    "    \"    if existing_model:\\n\",\n",
    "    \"        model_instance = existing_model # Use the pre-loaded model\\n\",\n",
    "    \"        print(\\\"Continuing training with existing model.\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        # Create a new model instance if no existing model was provided\\n\",\n",
    "    \"        model_instance = AgePredictionModel(img_size=(img_sizes, img_sizes))\\n\",\n",
    "    \"        print(\\\"Initializing a new model for training.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Compile the model (even if loaded, re-compiling ensures correct optimizer/metrics)\\n\",\n",
    "    \"    model_instance.compile_model(learning_rate=learning_rate)\\n\",\n",
    "    \"    # Print model summary to verify architecture\\n\",\n",
    "    \"    model_instance.model.summary()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"\\\\n--- Starting Model Training ---\\\")\\n\",\n",
    "    \"    # Define callbacks for training process\\n\",\n",
    "    \"    callbacks = [\\n\",\n",
    "    \"        # Save the best model based on validation MAE\\n\",\n",
    "    \"        tf.keras.callbacks.ModelCheckpoint(\\n\",\n",
    "    \"            model_save_path,\\n\",\n",
    "    \"            monitor='val_mae',  # Monitor validation MAE\\n\",\n",
    "    \"            save_best_only=True, # Save only the best model\\n\",\n",
    "    \"            mode='min',         # Minimize MAE\\n\",\n",
    "    \"            verbose=1\\n\",\n",
    "    \"        ),\\n\",\n",
    "    \"        # Reduce learning rate when validation MAE stops improving\\n\",\n",
    "    \"        tf.keras.callbacks.ReduceLROnPlateau(\\n\",\n",
    "    \"            monitor='val_mae',  # Monitor validation MAE\\n\",\n",
    "    \"            factor=0.5,         # Reduce LR by 50%\\n\",\n",
    "    \"            patience=5,         # Wait for 5 epochs before reducing\\n\",\n",
    "    \"            min_lr=0.00001,     # Minimum learning rate\\n\",\n",
    "    \"            verbose=1\\n\",\n",
    "    \"        ),\\n\",\n",
    "    \"        # Early stopping to prevent overfitting\\n\",\n",
    "    \"        tf.keras.callbacks.EarlyStopping(\\n\",\n",
    "    \"            monitor='val_mae',  # Monitor validation MAE\\n\",\n",
    "    \"            patience=10,        # Wait for 10 epochs before stopping\\n\",\n",
    "    \"            mode='min',         # Minimize MAE\\n\",\n",
    "    \"            restore_best_weights=True, # Restore best weights found during training\\n\",\n",
    "    \"            verbose=1\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"    ]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Train the model\\n\",\n",
    "    \"    history = model_instance.model.fit(\\n\",\n",
    "    \"        train_ds,\\n\",\n",
    "    \"        epochs=epochs,\\n\",\n",
    "    \"        validation_data=val_ds,\\n\",\n",
    "    \"        callbacks=callbacks\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"--- Model Training Finished ---\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Plot training history\\n\",\n",
    "    \"    plot_training_history(history, save_path=f'training_history_{os.path.basename(model_save_path).split('.')[0]}.png')\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.7. Evaluation Pipeline (from `src/testing/EvaluationPipeline.py`)\\n\",\n",
    "    \"\\n\",\n",
    "    \"This function performs model evaluation on the test dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def evaluation_pipeline(model_save_path: str, test_path: str, label_path: str, img_sizes: int, batch_size: int = 16):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Orchestrates the evaluation pipeline for the bone age prediction model.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        model_save_path (str): Path to the saved Keras model file.\\n\",\n",
    "    \"        test_path (str): Base directory for test data (e.g., 'data/Test/').\\n\",\n",
    "    \"        label_path (str): CSV file path for test labels (e.g., 'data/Test/test_labels.csv').\\n\",\n",
    "    \"        img_sizes (int): Side length for input images (e.g., 256 for 256x256).\\n\",\n",
    "    \"        batch_size (int): Batch size for evaluation. Defaults to 16.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    print(\\\"\\\\n--- Starting Model Evaluation ---\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Load the best model\\n\",\n",
    "    \"    model = load_trained_model(model_save_path=model_save_path)\\n\",\n",
    "    \"    if model is None:\\n\",\n",
    "    \"        print(f\\\"Error: Could not load model from {model_save_path}. Aborting evaluation.\\\")\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"\\\\n--- Setting up Test Dataset ---\\\")\\n\",\n",
    "    \"    # Calculate mean and std from training data (if not already done/known)\\n\",\n",
    "    \"    # This is crucial for consistent standardization during evaluation.\\n\",\n",
    "    \"    # You should ideally pass the mean_pixel_value and std_pixel_value from training.\\n\",\n",
    "    \"    # For simplicity here, we'll recalculate from a known training path if not provided.\\n\",\n",
    "    \"    # **IMPORTANT**: In a real scenario, these values should be saved from training\\n\",\n",
    "    \"    # and loaded here to ensure identical preprocessing.\\n\",\n",
    "    \"    train_prep_images_for_mean_std = 'data/Train/prep_images' # Assumed path for recalculating mean/std\\n\",\n",
    "    \"    if not os.path.exists(train_prep_images_for_mean_std):\\n\",\n",
    "    \"        print(f\\\"Warning: Training prep_images path '{train_prep_images_for_mean_std}' not found for mean/std calculation. Using default (0.0, 1.0). Ensure your data is preprocessed.\\\")\\n\",\n",
    "    \"        mean_val, std_val = 0.0, 1.0 # Fallback\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        mean_val, std_val = calculate_mean_std(train_prep_images_for_mean_std, img_size=(img_sizes, img_sizes))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    test_dataset_builder = RadiographDatasetBuilder(\\n\",\n",
    "    \"        base_dir=test_path,\\n\",\n",
    "    \"        label_csv=label_path,\\n\",\n",
    "    \"        img_size=(img_sizes, img_sizes),\\n\",\n",
    "    \"        batch_size=batch_size,\\n\",\n",
    "    \"        mean_pixel_value=mean_val,\\n\",\n",
    "    \"        std_pixel_value=std_val\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    test_ds = test_dataset_builder.build(train=False) # No shuffle for evaluation\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"\\\\n--- Performing Prediction ---\\\")\\n\",\n",
    "    \"    # Extract true labels and make predictions\\n\",\n",
    "    \"    true_months_list = []\\n\",\n",
    "    \"    pred_months_list = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Iterate over the dataset to get predictions and true values\\n\",\n",
    "    \"    for images, labels in test_ds:\\n\",\n",
    "    \"        predictions = model.predict(images)\\n\",\n",
    "    \"        true_months_list.extend(labels.numpy().flatten())\\n\",\n",
    "    \"        pred_months_list.extend(predictions.flatten())\\n\",\n",
    "    \"\\n\",\n",
    "    \"    true_months_array = np.array(true_months_list)\\n\",\n",
    "    \"    pred_months_array = np.array(pred_months_list)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Ensure predictions are non-negative, as bone age cannot be negative\\n\",\n",
    "    \"    pred_months_array[pred_months_array < 0] = 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Calculate absolute errors\\n\",\n",
    "    \"    errors = np.abs(true_months_array - pred_months_array)\\n\",\n",
    "    \"    mae = np.mean(errors)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(f\\\"\\\\n--- Evaluation Results ---\\\")\\n\",\n",
    "    \"    print(f\\\"Test MAE: {mae:.2f} months\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Plot evaluation results\\n\",\n",
    "    \"    plot_eval(errors, mae, true_months_array, pred_months_array)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"--- Model Evaluation Completed ---\\\")\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.8. Model Loading Utility (from `src/utils/load_model.py`)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def load_trained_model(model_save_path: str):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Loads a pre-trained Keras model from a specified path.\\n\",\n",
    "    \"    It handles custom objects like 'SpatialAttention' needed for model reconstruction.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        model_save_path (str): The file path from which to load the model.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Returns:\\n\",\n",
    "    \"        tf.keras.Model or None: The loaded Keras Model instance if successful, else None.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    if os.path.exists(model_save_path):\\n\",\n",
    "    \"        print(f\\\"\\\\nLoading model from '{model_save_path}'...\\\")\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            # Load the model, specifying the custom object for SpatialAttention\\n\",\n",
    "    \"            loaded_model = tf.keras.models.load_model(\\n\",\n",
    "    \"                model_save_path, custom_objects={'SpatialAttention': SpatialAttention}\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"            print(\\\"Model loaded successfully.\\\")\\n\",\n",
    "    \"            return loaded_model\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            # Catch any exceptions that occur during the model loading process.\\n\",\n",
    "    \"            # This can happen if the file is corrupted, the custom object is not found, etc.\\n\",\n",
    "    \"            print(f\\\"Error during model loading: {e}\\\")\\n\",\n",
    "    \"            import traceback\\n\",\n",
    "    \"            traceback.print_exc()  # Print the full stack trace for debugging purposes\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # If loading fails, treat it as if no model was found, and suggest starting anew.\\n\",\n",
    "    \"            print(\\\"Model loading failed. Proceeding with training a new model.\\\")\\n\",\n",
    "    \"            return None  # Indicate failure to load by returning None\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        # Inform the user if the model file does not exist.\\n\",\n",
    "    \"        print(f\\\"\\\\nModel not found at '{model_save_path}'. Starting training from scratch.\\\")\\n\",\n",
    "    \"        return None  # Indicate that no existing model was found\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.9. Evaluation Plotting (from `src/plot/plot_evaluation.py`)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def plot_eval(errors_list, mae_months, true_months_list, pred_months_list):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Generates and saves a series of plots to analyze the performance of\\n\",\n",
    "    \"    the age prediction model.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        errors_list (list/array): List of absolute prediction errors (months).\\n\",\n",
    "    \"        mae_months (float): Overall Mean Absolute Error (months).\\n\",\n",
    "    \"        true_months_list (list/array): List of true ages (months).\\n\",\n",
    "    \"        pred_months_list (list/array): List of predicted ages (months).\\n\",\n",
    "    \"        \\\"\\\"\\\"\\n\",\n",
    "    \"    plt.figure(figsize=(18, 12))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # 1. Distribution of absolute errors\\n\",\n",
    "    \"    plt.subplot(2, 2, 1)\\n\",\n",
    "    \"    sns.histplot(errors_list, kde=True, bins=30)\\n\",\n",
    "    \"    plt.axvline(mae_months, color='r', linestyle='--', label=f'MAE: {mae_months:.2f} months')\\n\",\n",
    "    \"    plt.xlabel('Absolute Error (months)')\\n\",\n",
    "    \"    plt.ylabel('Frequency')\\n\",\n",
    "    \"    plt.title('Distribution of Age Prediction Errors')\\n\",\n",
    "    \"    plt.legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # 2. Scatter plot: true age vs predicted age\\n\",\n",
    "    \"    plt.subplot(2, 2, 2)\\n\",\n",
    "    \"    plt.scatter(true_months_list, pred_months_list, alpha=0.5)\\n\",\n",
    "    \"    # Ideal y=x line\\n\",\n",
    "    \"    min_val = min(min(true_months_list), min(pred_months_list))\\n\",\n",
    "    \"    max_val = max(max(true_months_list), max(pred_months_list))\\n\",\n",
    "    \"    plt.plot([min_val, max_val], [min_val, max_val], 'r--', label='Ideal')\\n\",\n",
    "    \"    plt.xlabel('True Age (months)')\\n\",\n",
    "    \"    plt.ylabel('Predicted Age (months)')\\n\",\n",
    "    \"    plt.title('True Age vs Predicted Age')\\n\",\n",
    "    \"    plt.legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # 3. Box plot of errors by age group\\n\",\n",
    "    \"    plt.subplot(2, 2, 3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Create age bins\\n\",\n",
    "    \"    # Extended bins to cover a wider range if necessary\\n\",\n",
    "    \"    age_bins = [0, 36, 72, 120, 180, 240, 300]  # Years: 0-3, 3-6, 6-10, 10-15, 15-20, 20-25\\n\",\n",
    "    \"    age_labels = ['0-3', '3-6', '6-10', '10-15', '15-20', '20+']  # Corresponding to the bins\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Ensure age_bins covers the entire age range of your data\\n\",\n",
    "    \"    if max(true_months_list) > age_bins[-1]:\\n\",\n",
    "    \"        # Add a final bin if there are ages beyond the defined maximum\\n\",\n",
    "    \"        age_bins.append(int(max(true_months_list) + 12))  # Add one more year to the max\\n\",\n",
    "    \"        age_labels.append(f'{age_labels[-1]}+')  # Update the label for the last bin\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Create a pandas Series for age\\n\",\n",
    "    \"    age_series = pd.Series(true_months_list)\\n\",\n",
    "    \"    binned_ages = pd.cut(age_series, bins=age_bins, labels=age_labels, right=False)  # right=False for interval [a, b)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Create a DataFrame with age and errors\\n\",\n",
    "    \"    error_df = pd.DataFrame({\\n\",\n",
    "    \"        'Age_Group': binned_ages,\\n\",\n",
    "    \"        'Absolute_Error': errors_list\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Box plot\\n\",\n",
    "    \"    sns.boxplot(x='Age_Group', y='Absolute_Error', data=error_df)\\n\",\n",
    "    \"    plt.xlabel('Age Group (years)')\\n\",\n",
    "    \"    plt.ylabel('Absolute Error (months)')\\n\",\n",
    "    \"    plt.title('Distribution of Errors by Age Group')\\n\",\n",
    "    \"    plt.xticks(rotation=45)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # 4. Heatmap: error based on true vs predicted age\\n\",\n",
    "    \"    plt.subplot(2, 2, 4)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Convert months to years for readability\\n\",\n",
    "    \"    true_years_array = np.array(true_months_list) / 12\\n\",\n",
    "    \"    pred_years_array = np.array(pred_months_list) / 12\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Define bins for years (e.g., 0-4, 4-8, 8-12, 12-16, 16-20, 20+)\\n\",\n",
    "    \"    # Use a step for the bins and ensure they cover the entire age range\\n\",\n",
    "    \"    max_age_in_years = max(np.max(true_years_array), np.max(pred_years_array))\\n\",\n",
    "    \"    # Create dynamic bins that include all existing ages\\n\",\n",
    "    \"    # Example: bins every 4 years, but the last bin includes the maximum\\n\",\n",
    "    \"    bins_years = np.arange(0, max_age_in_years + 5, 4)  # Add a little margin\\n\",\n",
    "    \"    if max_age_in_years > bins_years[-1]:  # Ensure the last bin covers the maximum\\n\",\n",
    "    \"        bins_years = np.append(bins_years, max_age_in_years + 1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Calculate 2D distributions with np.histogram2d\\n\",\n",
    "    \"    heatmap, xedges, yedges = np.histogram2d(true_years_array, pred_years_array, bins=[bins_years, bins_years])\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Normalize by row to show the distribution of predictions for each true age group\\n\",\n",
    "    \"    row_sums = heatmap.sum(axis=1, keepdims=True)\\n\",\n",
    "    \"    heatmap_norm = np.divide(heatmap, row_sums, out=np.zeros_like(heatmap), where=row_sums != 0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Create labels for the heatmap axes\\n\",\n",
    "    \"    x_labels = [f'{int(xedges[i])}-{int(xedges[i + 1])}' if i < len(xedges) - 2 else f'{int(xedges[i])}+' for i in\\n\",\n",
    "    \"                range(len(xedges) - 1)]\\n\",\n",
    "    \"    y_labels = [f'{int(yedges[i])}-{int(yedges[i + 1])}' if i < len(yedges) - 2 else f'{int(yedges[i])}+' for i in\\n\",\n",
    "    \"                range(len(yedges) - 1)]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    sns.heatmap(heatmap_norm, cmap='YlGnBu', annot=True, fmt=\\\".2f\\\",\\n\",\n",
    "    \"                xticklabels=x_labels,\\n\",\n",
    "    \"                yticklabels=y_labels)\\n\",\n",
    "    \"    plt.xlabel('Predicted Age (years)')\\n\",\n",
    "    \"    plt.ylabel('True Age (years)')\\n\",\n",
    "    \"    plt.title('Distribution of Predictions by Age Group (Row Normalized)')\\n\",\n",
    "    \"\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.savefig('age_prediction_analysis.png', dpi=300)\\n\",\n",
    "    \"    plt.show()\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.10. Training History Plotting (from `src/plot/plot_training_history.py`)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def plot_training_history(history: History, save_path: str = 'training_history_plots.png'):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Generates and saves plots of the loss and MAE from the training and validation history.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        history (tf.keras.callbacks.History): The History object returned by model.fit().\\n\",\n",
    "    \"        save_path (str): The full path where the plot will be saved.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    if not isinstance(history, History):\\n\",\n",
    "    \"        print(\\\"Error: 'history' must be an instance of tf.keras.callbacks.History.\\\")\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"\\n\",\n",
    "    \"    hist = history.history\\n\",\n",
    "    \"    epochs = range(1, len(hist['loss']) + 1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    plt.figure(figsize=(15, 6))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Plot of Loss\\n\",\n",
    "    \"    plt.subplot(1, 2, 1)\\n\",\n",
    "    \"    plt.plot(epochs, hist['loss'], label='Training Loss')\\n\",\n",
    "    \"    if 'val_loss' in hist:\\n\",\n",
    "    \"        plt.plot(epochs, hist['val_loss'], label='Validation Loss')\\n\",\n",
    "    \"    plt.title('Loss Curve During Training')\\n\",\n",
    "    \"    plt.xlabel('Epoch')\\n\",\n",
    "    \"    plt.ylabel('Loss (MAE)')\\n\",\n",
    "    \"    plt.legend()\\n\",\n",
    "    \"    plt.grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Plot of MAE\\n\",\n",
    "    \"    plt.subplot(1, 2, 2)\\n\",\n",
    "    \"    plt.plot(epochs, hist['mae'], label='Training MAE')\\n\",\n",
    "    \"    if 'val_mae' in hist:\\n\",\n",
    "    \"        plt.plot(epochs, hist['val_mae'], label='Validation MAE')\\n\",\n",
    "    \"    plt.title('MAE Curve During Training')\\n\",\n",
    "    \"    plt.xlabel('Epoch')\\n\",\n",
    "    \"    plt.ylabel('MAE (Months)')\\n\",\n",
    "    \"    plt.legend()\\n\",\n",
    "    \"    plt.grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.savefig(save_path, dpi=300)\\n\",\n",
    "    \"    print(f\\\"\\\\nTraining history plots saved as '{save_path}'.\\\")\\n\",\n",
    "    \"    plt.show() # Display the plot\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Global Constants\\n\",\n",
    "    \"\\n\",\n",
    "    \"Definition of constants used in the pipeline.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# --- Global Constants ---\\n\",\n",
    "    \"MODEL_PATH = 'best_age_prediction_model.keras'\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"str: The default file path for saving and loading the best trained Keras model.\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"TARGET_IMG_SIZE = 256\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"int: The target size (height and width) in pixels for preprocessed images.\\n\",\n",
    "    \"     Images will be resized to (TARGET_IMG_SIZE, TARGET_IMG_SIZE).\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Main Pipeline Orchestrator (`radiograph_pipeline`)\\n\",\n",
    "    \"\\n\",\n",
    "    \"This is the main function that coordinates the entire bone age assessment pipeline, controlling the preprocessing, training, and evaluation phases based on the provided flags.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def radiograph_pipeline(preprocess: bool = False, training: bool = False, evaluate: bool = False):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Main pipeline orchestrator for bone age assessment from radiographs.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    This function controls the entire workflow, including data preprocessing,\\n\",\n",
    "    \"    model training, and model evaluation, based on the boolean flags provided.\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        preprocess (bool, optional): If True, executes the image preprocessing pipeline\\n\",\n",
    "    \"                                     for training, validation, and test datasets.\\n\",\n",
    "    \"                                     This creates standardized image files. Defaults to False.\\n\",\n",
    "    \"        training (bool, optional): If True, executes the model training pipeline.\\n\",\n",
    "    \"                                   It calculates mean/std for standardization, loads an\\n\",\n",
    "    \"                                   existing model (if available), and initiates training.\\n\",\n",
    "    \"                                   Defaults to False.\\n\",\n",
    "    \"        evaluate (bool, optional): If True, executes the model evaluation pipeline on\\n\",\n",
    "    \"                                   the test dataset using the best saved model. Defaults to False.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # --- Phase 1: Data Preprocessing ---\\n\",\n",
    "    \"    # This block performs image preprocessing (hand detection, CLAHE, resizing, augmentation)\\n\",\n",
    "    \"    # and saves the processed images to specified 'prep_images' directories.\\n\",\n",
    "    \"    # It needs to be run once to prepare the dataset for training/evaluation.\\n\",\n",
    "    \"    if preprocess:\\n\",\n",
    "    \"        print(\\\"\\\\n--- Starting Data Preprocessing ---\\\")\\n\",\n",
    "    \"        preprocess_pipeline('data/Val/', Val=True) # Assuming Val=True implies 'val_labels.csv' and 'raw_images'\\n\",\n",
    "    \"        preprocess_pipeline('data/Test/', Test=True, Val=False) # Val=False ensures it's treated as Test\\n\",\n",
    "    \"        preprocess_pipeline('data/Train/', Train=True, Val=False) # Val=False ensures it's treated as Train\\n\",\n",
    "    \"        print(\\\"--- Data Preprocessing Completed ---\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # --- Phase 2: Model Training ---\\n\",\n",
    "    \"    # This block handles the training of the deep learning model.\\n\",\n",
    "    \"    # It calculates standardization parameters, attempts to load a previously\\n\",\n",
    "    \"    # trained model to continue training, and then runs the training pipeline.\\n\",\n",
    "    \"    if training:\\n\",\n",
    "    \"        print(\\\"\\\\n--- Starting Model Training ---\\\")\\n\",\n",
    "    \"        # Define base directories and label CSVs for training and validation datasets.\\n\",\n",
    "    \"        # These paths assume a specific directory structure for your data.\\n\",\n",
    "    \"        base_dir_train = 'data/Train'\\n\",\n",
    "    \"        base_dir_val = 'data/Val'\\n\",\n",
    "    \"        label_train_csv = os.path.join(base_dir_train, 'train_labels.csv')  # Assuming specific CSV names\\n\",\n",
    "    \"        label_val_csv = os.path.join(base_dir_val, 'val_labels.csv')\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Calculate mean and standard deviation of pixel values from the preprocessed\\n\",\n",
    "    \"        # training images. These values are crucial for standardizing all datasets\\n\",\n",
    "    \"        # (train, validation, test) to ensure consistency during model inference.\\n\",\n",
    "    \"        train_prep_images_path = os.path.join(base_dir_train, 'prep_images')\\n\",\n",
    "    \"        mean_val, std_val = calculate_mean_std(train_prep_images_path, img_size=(TARGET_IMG_SIZE, TARGET_IMG_SIZE))\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Attempt to load a pre-trained model. If MODEL_PATH exists and the model\\n\",\n",
    "    \"        # can be loaded, training will resume from its current state. Otherwise,\\n\",\n",
    "    \"        # a new model will be initialized from scratch.\\n\",\n",
    "    \"        model = load_trained_model(model_save_path=MODEL_PATH)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Execute the training pipeline.\\n\",\n",
    "    \"        # It orchestrates dataset loading, model compilation, and the training loop\\n\",\n",
    "    \"        # using the calculated standardization values and the loaded/new model.\\n\",\n",
    "    \"        training_pipeline(base_dir_train=base_dir_train,\\n\",\n",
    "    \"                          label_train=label_train_csv,\\n\",\n",
    "    \"                          label_val=label_val_csv,\\n\",\n",
    "    \"                          base_dir_val=base_dir_val,\\n\",\n",
    "    \"                          img_sizes=TARGET_IMG_SIZE,\\n\",\n",
    "    \"                          mean_pixel_value=mean_val,\\n\",\n",
    "    \"                          std_pixel_value=std_val,\\n\",\n",
    "    \"                          existing_model=model,  # Pass the loaded model (or None if new)\\n\",\n",
    "    \"                          model_save_path=MODEL_PATH)\\n\",\n",
    "    \"        print(\\\"--- Model Training Completed ---\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # --- Phase 3: Model Evaluation ---\\n\",\n",
    "    \"    # This block evaluates the performance of the best saved model on the test dataset.\\n\",\n",
    "    \"    # It uses the same standardization parameters from training for consistency.\\n\",\n",
    "    \"    if evaluate:\\n\",\n",
    "    \"        print(\\\"\\\\n--- Starting Model Evaluation ---\\\")\\n\",\n",
    "    \"        # Define base directories and label CSV for the test dataset.\\n\",\n",
    "    \"        base_dir_test = 'data/Test'\\n\",\n",
    "    \"        label_test_csv = os.path.join(base_dir_test, 'test_labels.csv')\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Execute the evaluation pipeline.\\n\",\n",
    "    \"        # It loads the best saved model and evaluates it on the test dataset,\\n\",\n",
    "    \"        # applying the same standardization used during training.\\n\",\n",
    "    \"        evaluation_pipeline(model_save_path=MODEL_PATH,\\n\",\n",
    "    \"                            test_path=base_dir_test,\\n\",\n",
    "    \"                            label_path=label_test_csv,\\n\",\n",
    "    \"                            img_sizes=TARGET_IMG_SIZE)\\n\",\n",
    "    \"        print(\\\"--- Model Evaluation Completed ---\\\")\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Main Pipeline Execution\\n\",\n",
    "    \"\\n\",\n",
    "    \"This section shows how to call the `radiograph_pipeline` function to execute different phases of the workflow. Uncomment the appropriate calls based on what you want to execute.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"if __name__ == '__main__':\\n\",\n",
    "    \"    # Example of pipeline usage:\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # 1. Data Preprocessing\\n\",\n",
    "    \"    # This step should be executed once to prepare the images.\\n\",\n",
    "    \"    # radiograph_pipeline(preprocess=True, training=False, evaluate=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # 2. Model Training\\n\",\n",
    "    \"    # Ensure that the data has been preprocessed before running training.\\n\",\n",
    "    \"    # If a model already exists at MODEL_PATH, training will resume from there.\\n\",\n",
    "    \"    # radiograph_pipeline(preprocess=False, training=True, evaluate=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # 3. Model Evaluation\\n\",\n",
    "    \"    # Ensure that a model has been trained and saved at MODEL_PATH.\\n\",\n",
    "    \"    radiograph_pipeline(preprocess=False, training=False, evaluate=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # You can also combine steps, but it's advisable to run them separately for clarity and debugging.\\n\",\n",
    "    \"    # Example: Run preprocessing AND training (preprocessing only starts if necessary)\\n\",\n",
    "    \"    # radiograph_pipeline(preprocess=True, training=True, evaluate=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Example: Run training AND evaluation\\n\",\n",
    "    \"    # radiograph_pipeline(preprocess=False, training=True, evaluate=True)\\n\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.18\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ],
   "id": "9e43899400ac83a1"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
